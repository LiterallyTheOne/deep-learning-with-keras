{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6081be9259b22e",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center; color: cyan\">Add preprocessing and Augmentation</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d50d16fe7ca18",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center; color: lime\">Setup</div>"
   ]
  },
  {
   "cell_type": "code",
   "id": "7a0b8fd5d1f95223",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7b3bc70a07f386dd",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center; color: lime\">Imports</div>"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "import datetime"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "66eecc9c6e21df63",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center; color: lime\">Load the data</div>"
   ]
  },
  {
   "cell_type": "code",
   "id": "aaae9f282b3fe51f",
   "metadata": {},
   "source": [
    "path = kagglehub.dataset_download(\"balabaskar/tom-and-jerry-image-classification\")\n",
    "\n",
    "data_path = Path(path) / \"tom_and_jerry/tom_and_jerry\"\n",
    "\n",
    "trs = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "all_data = ImageFolder(data_path, transform=trs)\n",
    "\n",
    "g1 = torch.Generator().manual_seed(20)\n",
    "train_data, val_data, test_data = random_split(all_data, [0.7, 0.2, 0.1], g1)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=12, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=12, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=12, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a9e18a91aeb49368",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(3, 4)\n",
    "\n",
    "axes_ravel = axes.ravel()\n",
    "\n",
    "for images, labels in val_loader:\n",
    "    for i, (image, label) in enumerate(zip(images, labels)):\n",
    "        axes_ravel[i].imshow(transforms.ToPILImage()(image))\n",
    "        axes_ravel[i].set_axis_off()\n",
    "        axes_ravel[i].set_title(f\"{label}\")\n",
    "    break"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d2d223619012cb0d",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center; color: lime\">Make the model</div>"
   ]
  },
  {
   "cell_type": "code",
   "id": "892c0e50bf8a50a0",
   "metadata": {},
   "source": [
    "base_model = MobileNetV2(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "augmentation_layers = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomFlip(\"vertical\"),\n",
    "        layers.RandomZoom(0.1, 0.1),\n",
    "        layers.RandomTranslation(0.05, 0.05),\n",
    "        layers.RandomRotation(0.05),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(3, 224, 224)),\n",
    "        layers.Permute((2, 3, 1)),\n",
    "        layers.Lambda(preprocess_input),\n",
    "        augmentation_layers,\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d335c6d98da3019c",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center; color: lime\">Train the model</div>"
   ]
  },
  {
   "cell_type": "code",
   "id": "b27a32f0c87fa7fc",
   "metadata": {},
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "history = model.fit(\n",
    "    train_loader,\n",
    "    epochs=10,\n",
    "    validation_data=val_loader,\n",
    "    callbacks=[tensorboard_callback],\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d5a24de655c585cc",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center; color: lime\">Evalute the model</div>"
   ]
  },
  {
   "cell_type": "code",
   "id": "6cd3a8608a4da1db",
   "metadata": {},
   "source": [
    "loss, accuracy = model.evaluate(test_loader)\n",
    "\n",
    "print(\"loss:\", loss)\n",
    "print(\"accuracy:\", accuracy)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ab9e15ce1094c88",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center; color: lime\">Plot the training procedure</div>"
   ]
  },
  {
   "cell_type": "code",
   "id": "2feefe7ed1680290",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "plt.title(\"loss\")\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend([\"loss\", \"val_loss\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "28123350b50fc253",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "plt.title(\"accuracy\")\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.legend([\"accuracy\", \"val_accuracy\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dbaea817c305037b",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-family: \"Trebuchet MS\", sans-serif; color: #888; font-size: 0.9em; margin-top: 2em; border-top: 1px solid #ccc; padding-top: 0.5em;\">\n",
    "    @LiterallyTheOne â€” PhD Candidate in Artificial Intelligence\n",
    "</p>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<a style=\"margin: 1em\" href=\"https://literallytheone.github.io\">https://literallytheone.github.io</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
